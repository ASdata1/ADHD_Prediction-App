{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a99c885f",
   "metadata": {},
   "source": [
    "## Uploading Data \n",
    "\n",
    "Uploading Categorical, Quantitative and Connectome Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e821b4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ADHD Prediction Dataset - Data Merging Module\n",
    "\n",
    "This notebook merges multiple ADHD-related datasets into a single comprehensive dataset\n",
    "for machine learning analysis. The merged dataset combines neuroimaging connectome data,\n",
    "behavioral questionnaires, demographic information, and target labels.\n",
    "\n",
    "\n",
    "Project: ADHD Sex Prediction\n",
    "Input Files: 4 separate datasets (connectome, quantitative, categorical, targets)\n",
    "Output: Unified raw dataset for preprocessing pipeline\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# =============================================================================\n",
    "# CONFIGURATION AND FILE PATHS\n",
    "# =============================================================================\n",
    "\n",
    "# Data file paths\n",
    "DATA_DIR = Path(\"C:/Users/04ama/Downloads\")\n",
    "OUTPUT_DIR = Path(\".\")\n",
    "\n",
    "# Input file paths\n",
    "CONNECTOME_FILE = DATA_DIR / \"TRAIN_FUNCTIONAL_CONNECTOME_MATRICES_new_36P_Pearson (1).csv\"\n",
    "QUANTITATIVE_FILE = DATA_DIR / \"TRAIN_QUANTITATIVE_METADATA_new.xlsx\"\n",
    "CATEGORICAL_FILE = DATA_DIR / \"TRAIN_CATEGORICAL_METADATA_new.xlsx\"\n",
    "TARGET_FILE = DATA_DIR / \"TRAINING_SOLUTIONS (1).xlsx\"\n",
    "\n",
    "# Output file\n",
    "OUTPUT_FILE = OUTPUT_DIR / \"raw_dataset.csv\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25e6f3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# DATA LOADING FUNCTIONS\n",
    "# =============================================================================\n",
    "\n",
    "def load_dataset(file_path, dataset_name, file_type='csv'):\n",
    "    \"\"\"\n",
    "    Load a dataset with error handling and basic validation.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    file_path : str or Path\n",
    "        Path to the data file\n",
    "    dataset_name : str\n",
    "        Human-readable name for logging\n",
    "    file_type : str\n",
    "        File format ('csv' or 'excel')\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        Loaded dataset\n",
    "    \n",
    "    Raises:\n",
    "    -------\n",
    "    FileNotFoundError\n",
    "        If the file doesn't exist\n",
    "    pd.errors.EmptyDataError\n",
    "        If the file is empty\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"Loading {dataset_name} data\")\n",
    "        \n",
    "        if file_type == 'csv':\n",
    "            df = pd.read_csv(file_path)\n",
    "        elif file_type == 'excel':\n",
    "            df = pd.read_excel(file_path)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported file type: {file_type}\")\n",
    "\n",
    "        print(f\"Successfully loaded: {df.shape[0]:,} rows √ó {df.shape[1]:,} columns\")\n",
    "        return df\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\" Error: File not found - {file_path}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {dataset_name}: {str(e)}\")\n",
    "        raise\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c530ae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Connectome data\n",
      "Successfully loaded: 1,213 rows √ó 19,901 columns\n",
      "Loading Quantitative data\n",
      "Successfully loaded: 1,213 rows √ó 19 columns\n",
      "Loading Categorical data\n",
      "Successfully loaded: 1,213 rows √ó 10 columns\n",
      "Loading Target data\n",
      "Successfully loaded: 1,213 rows √ó 3 columns\n",
      "\n",
      " Dataset Summary:\n",
      "Connectome      1213     19901    \n",
      "Quantitative    1213     19       \n",
      "Categorical     1213     10       \n",
      "Target          1213     3        \n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# DATASET LOADING \n",
    "# =============================================================================\n",
    "\n",
    "# Load Connectome Data (Functional brain connectivity matrices)\n",
    "conn_data = load_dataset(CONNECTOME_FILE, \"Connectome\", \"csv\")\n",
    "\n",
    "\n",
    "# Load Quantitative Metadata (Behavioral questionnaires and assessments)\n",
    "quant_data = load_dataset(QUANTITATIVE_FILE, \"Quantitative\", \"excel\")\n",
    "\n",
    "\n",
    "# Load Categorical Metadata (Demographics and categorical variables)\n",
    "cat_data = load_dataset(CATEGORICAL_FILE, \"Categorical\", \"excel\")\n",
    "\n",
    "\n",
    "# Load Target Data (ADHD outcome labels)\n",
    "target_data = load_dataset(TARGET_FILE, \"Target\", \"excel\")\n",
    "\n",
    "\n",
    "print(f\"\\n Dataset Summary:\")\n",
    "\n",
    "print(f\"{'Connectome':<15} {conn_data.shape[0]:<8} {conn_data.shape[1]:<8} \")\n",
    "print(f\"{'Quantitative':<15} {quant_data.shape[0]:<8} {quant_data.shape[1]:<8} \")\n",
    "print(f\"{'Categorical':<15} {cat_data.shape[0]:<8} {cat_data.shape[1]:<8} \")\n",
    "print(f\"{'Target':<15} {target_data.shape[0]:<8} {target_data.shape[1]:<8} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e5be6f10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant_id</th>\n",
       "      <th>ADHD_Outcome</th>\n",
       "      <th>Sex_F</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UmrK0vMLopoR</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CPaeQkhcjg7d</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nb4EetVPm3gs</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p4vPhVu91o4b</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M09PXs7arQ5E</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  participant_id  ADHD_Outcome  Sex_F\n",
       "0   UmrK0vMLopoR             1      1\n",
       "1   CPaeQkhcjg7d             1      0\n",
       "2   Nb4EetVPm3gs             1      0\n",
       "3   p4vPhVu91o4b             1      1\n",
       "4   M09PXs7arQ5E             1      1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78f1c7f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Step 1: Added Quantitative\n",
      "            ‚Ä¢ Rows: 1,213 ‚Üí 1,213 (+0)\n",
      "            ‚Ä¢ Cols: 19,901 ‚Üí 19,919 (+18)\n",
      "   Step 2: Added Categorical\n",
      "            ‚Ä¢ Rows: 1,213 ‚Üí 1,213 (+0)\n",
      "            ‚Ä¢ Cols: 19,919 ‚Üí 19,928 (+9)\n",
      "   Step 3: Added Target\n",
      "            ‚Ä¢ Rows: 1,213 ‚Üí 1,213 (+0)\n",
      "            ‚Ä¢ Cols: 19,928 ‚Üí 19,930 (+2)\n",
      "Final dataset shape: 1,213 rows √ó 19,930 columns\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# DATA MERGING PROCESS\n",
    "# =============================================================================\n",
    "\n",
    "def merge_datasets_sequentially(datasets, dataset_names, key='participant_id'):\n",
    "    \"\"\"\n",
    "    Sequentially merge multiple datasets on a common key.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    datasets : list of pd.DataFrame\n",
    "        List of datasets to merge\n",
    "    dataset_names : list of str\n",
    "        Names of datasets for logging\n",
    "    merge_key : str\n",
    "        Column name to merge on\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        Final merged dataset\n",
    "    \n",
    "    Notes:\n",
    "    ------\n",
    "    Uses inner joins to ensure only participants with data in ALL datasets\n",
    "    are included in the final merged dataset.\n",
    "    \"\"\"\n",
    "  \n",
    "    \n",
    "    # Start with first dataset\n",
    "    merged_df = datasets[0].copy()\n",
    "\n",
    "    \n",
    "    #  merge remaining datasets\n",
    "    for i, (dataset, name) in enumerate(zip(datasets[1:], dataset_names[1:]), 1):\n",
    "        before_shape = merged_df.shape\n",
    "        \n",
    "        # Perform inner join to keep only matching participant_ids\n",
    "        merged_df = pd.merge(merged_df, dataset, on=key, how='inner')\n",
    "        after_shape = merged_df.shape\n",
    "        \n",
    "        # Calculate merge statistics\n",
    "        rows_lost = before_shape[0] - after_shape[0]\n",
    "        cols_added = after_shape[1] - before_shape[1]\n",
    "        \n",
    "        print(f\"   Step {i}: Added {name}\")\n",
    "        print(f\"            ‚Ä¢ Rows: {before_shape[0]:,} ‚Üí {after_shape[0]:,} ({-rows_lost:+,})\")\n",
    "        print(f\"            ‚Ä¢ Cols: {before_shape[1]:,} ‚Üí {after_shape[1]:,} ({cols_added:+,})\")\n",
    "        \n",
    "        \n",
    "    return merged_df\n",
    "\n",
    "# Perform sequential merging\n",
    "datasets = [conn_data, quant_data, cat_data, target_data]\n",
    "dataset_names = [\"Connectome\", \"Quantitative\", \"Categorical\", \"Target\"]\n",
    "\n",
    "merged_df = merge_datasets_sequentially(datasets, dataset_names)\n",
    "\n",
    "print(f\"Final dataset shape: {merged_df.shape[0]:,} rows √ó {merged_df.shape[1]:,} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c66f018d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Dataset saved: raw_dataset.csv\n",
      "   üìÅ File size: 446.5 MB\n",
      "üìä Final dataset: 1,213 participants √ó 19,930 features\n",
      "üìÅ Output file: raw_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# DATA EXPORT AND SUMMARY\n",
    "# =============================================================================\n",
    "\n",
    "def save_merged_dataset(df, output_path):\n",
    "    \"\"\"\n",
    "    Save merged dataset with metadata documentation.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        Merged dataset to save\n",
    "    output_path : str or Path\n",
    "        Output file path\n",
    "    validation_report : dict\n",
    "        Validation statistics for documentation\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        # Save main dataset\n",
    "        df.to_csv(output_path, index=False)\n",
    "        file_size_mb = Path(output_path).stat().st_size / (1024*1024)\n",
    "        \n",
    "        print(f\"   ‚úÖ Dataset saved: {output_path}\")\n",
    "        print(f\"   üìÅ File size: {file_size_mb:.1f} MB\")\n",
    "        \n",
    "        # Create metadata file\n",
    "        metadata = {\n",
    "            'creation_date': pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            'source_files': {\n",
    "                'connectome': str(CONNECTOME_FILE),\n",
    "                'quantitative': str(QUANTITATIVE_FILE),\n",
    "                'categorical': str(CATEGORICAL_FILE),\n",
    "                'target': str(TARGET_FILE)\n",
    "            },\n",
    "            'merge_method': 'inner_join',\n",
    "            'merge_key': 'participant_id'\n",
    "        }\n",
    "        \n",
    "        # Save metadata\n",
    "        metadata_path = output_path.with_suffix('.json')\n",
    "        import json\n",
    "        with open(metadata_path, 'w') as f:\n",
    "            json.dump(metadata, f, indent=2, default=str)\n",
    "        \n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Error saving dataset: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "# Save the merged dataset\n",
    "save_merged_dataset(merged_df, OUTPUT_FILE)\n",
    "\n",
    "\n",
    "print(f\"üìä Final dataset: {merged_df.shape[0]:,} participants √ó {merged_df.shape[1]:,} features\")\n",
    "print(f\"üìÅ Output file: {OUTPUT_FILE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "536859d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant_id</th>\n",
       "      <th>0throw_1thcolumn</th>\n",
       "      <th>0throw_2thcolumn</th>\n",
       "      <th>0throw_3thcolumn</th>\n",
       "      <th>0throw_4thcolumn</th>\n",
       "      <th>0throw_5thcolumn</th>\n",
       "      <th>0throw_6thcolumn</th>\n",
       "      <th>0throw_7thcolumn</th>\n",
       "      <th>0throw_8thcolumn</th>\n",
       "      <th>0throw_9thcolumn</th>\n",
       "      <th>...</th>\n",
       "      <th>Basic_Demos_Study_Site</th>\n",
       "      <th>PreInt_Demos_Fam_Child_Ethnicity</th>\n",
       "      <th>PreInt_Demos_Fam_Child_Race</th>\n",
       "      <th>MRI_Track_Scan_Location</th>\n",
       "      <th>Barratt_Barratt_P1_Edu</th>\n",
       "      <th>Barratt_Barratt_P1_Occ</th>\n",
       "      <th>Barratt_Barratt_P2_Edu</th>\n",
       "      <th>Barratt_Barratt_P2_Occ</th>\n",
       "      <th>ADHD_Outcome</th>\n",
       "      <th>Sex_F</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>70z8Q2xdTXM3</td>\n",
       "      <td>0.222930</td>\n",
       "      <td>0.527903</td>\n",
       "      <td>0.429966</td>\n",
       "      <td>0.060457</td>\n",
       "      <td>0.566489</td>\n",
       "      <td>0.315342</td>\n",
       "      <td>0.508408</td>\n",
       "      <td>-0.078290</td>\n",
       "      <td>0.525692</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WHWymJu6zNZi</td>\n",
       "      <td>0.614765</td>\n",
       "      <td>0.577255</td>\n",
       "      <td>0.496127</td>\n",
       "      <td>0.496606</td>\n",
       "      <td>0.404686</td>\n",
       "      <td>0.439724</td>\n",
       "      <td>0.122590</td>\n",
       "      <td>-0.085452</td>\n",
       "      <td>0.120673</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4PAQp1M6EyAo</td>\n",
       "      <td>-0.116833</td>\n",
       "      <td>0.458408</td>\n",
       "      <td>0.260703</td>\n",
       "      <td>0.639031</td>\n",
       "      <td>0.769337</td>\n",
       "      <td>0.442528</td>\n",
       "      <td>0.637110</td>\n",
       "      <td>0.192010</td>\n",
       "      <td>0.520379</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>obEacy4Of68I</td>\n",
       "      <td>0.199688</td>\n",
       "      <td>0.752714</td>\n",
       "      <td>0.658283</td>\n",
       "      <td>0.575096</td>\n",
       "      <td>0.692867</td>\n",
       "      <td>0.645789</td>\n",
       "      <td>0.522750</td>\n",
       "      <td>0.412188</td>\n",
       "      <td>0.530843</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>s7WzzDcmDOhF</td>\n",
       "      <td>0.227321</td>\n",
       "      <td>0.613268</td>\n",
       "      <td>0.621447</td>\n",
       "      <td>0.562673</td>\n",
       "      <td>0.736709</td>\n",
       "      <td>0.589813</td>\n",
       "      <td>0.266676</td>\n",
       "      <td>0.359668</td>\n",
       "      <td>0.300771</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 19930 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  participant_id  0throw_1thcolumn  0throw_2thcolumn  0throw_3thcolumn  \\\n",
       "0   70z8Q2xdTXM3          0.222930          0.527903          0.429966   \n",
       "1   WHWymJu6zNZi          0.614765          0.577255          0.496127   \n",
       "2   4PAQp1M6EyAo         -0.116833          0.458408          0.260703   \n",
       "3   obEacy4Of68I          0.199688          0.752714          0.658283   \n",
       "4   s7WzzDcmDOhF          0.227321          0.613268          0.621447   \n",
       "\n",
       "   0throw_4thcolumn  0throw_5thcolumn  0throw_6thcolumn  0throw_7thcolumn  \\\n",
       "0          0.060457          0.566489          0.315342          0.508408   \n",
       "1          0.496606          0.404686          0.439724          0.122590   \n",
       "2          0.639031          0.769337          0.442528          0.637110   \n",
       "3          0.575096          0.692867          0.645789          0.522750   \n",
       "4          0.562673          0.736709          0.589813          0.266676   \n",
       "\n",
       "   0throw_8thcolumn  0throw_9thcolumn  ...  Basic_Demos_Study_Site  \\\n",
       "0         -0.078290          0.525692  ...                       1   \n",
       "1         -0.085452          0.120673  ...                       1   \n",
       "2          0.192010          0.520379  ...                       1   \n",
       "3          0.412188          0.530843  ...                       1   \n",
       "4          0.359668          0.300771  ...                       1   \n",
       "\n",
       "   PreInt_Demos_Fam_Child_Ethnicity  PreInt_Demos_Fam_Child_Race  \\\n",
       "0                               0.0                          1.0   \n",
       "1                               1.0                          8.0   \n",
       "2                               0.0                          0.0   \n",
       "3                               0.0                          0.0   \n",
       "4                               2.0                          8.0   \n",
       "\n",
       "   MRI_Track_Scan_Location  Barratt_Barratt_P1_Edu  Barratt_Barratt_P1_Occ  \\\n",
       "0                      2.0                    21.0                    45.0   \n",
       "1                      1.0                     6.0                     5.0   \n",
       "2                      2.0                    18.0                    35.0   \n",
       "3                      2.0                    21.0                    40.0   \n",
       "4                      2.0                     9.0                    35.0   \n",
       "\n",
       "   Barratt_Barratt_P2_Edu  Barratt_Barratt_P2_Occ  ADHD_Outcome  Sex_F  \n",
       "0                    21.0                    45.0             1      0  \n",
       "1                     NaN                    15.0             1      1  \n",
       "2                     9.0                    20.0             1      1  \n",
       "3                    21.0                    40.0             1      1  \n",
       "4                     NaN                     NaN             1      1  \n",
       "\n",
       "[5 rows x 19930 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80633141",
   "metadata": {},
   "source": [
    "DONE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
